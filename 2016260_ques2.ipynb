{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T' 2 8 3 5 1 8 13 0 6 6 10 8 0 8 0 8]\n",
      "[[2 8 3 ... 8 0 8]\n",
      " [5 12 3 ... 8 4 10]\n",
      " [4 11 6 ... 7 3 9]\n",
      " ...\n",
      " [6 9 6 ... 12 2 4]\n",
      " [2 3 4 ... 9 5 8]\n",
      " [4 9 6 ... 7 2 8]]\n",
      "['T' 'I' 'D' ... 'T' 'S' 'A']\n"
     ]
    }
   ],
   "source": [
    "X= np.array(pd.read_csv('./letter-recognition.data'))\n",
    "print (X[0])\n",
    "images=X[:,1:]\n",
    "label=X[:,0]\n",
    "print(images)\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000 6000\n",
      "['H' 'N' 'M' 'Y' 'Z' 'B' 'T' 'R' 'G' 'V']\n"
     ]
    }
   ],
   "source": [
    "#PART A\n",
    "randarray= np.arange(len(X))\n",
    "np.random.shuffle(randarray)\n",
    "breakpt= round(0.7*len(images))\n",
    "X_train= []\n",
    "Y_train= []\n",
    "X_test= []\n",
    "Y_test= []\n",
    "for i in range(breakpt):\n",
    "    X_train.append(images[randarray[i]])\n",
    "    Y_train.append(label[randarray[i]])\n",
    "for i in range(breakpt, len(images)):\n",
    "    X_test.append(images[randarray[i]])\n",
    "    Y_test.append(label[randarray[i]])\n",
    "    \n",
    "print (len(X_train), len(X_test))\n",
    "X_train= np.array(X_train)\n",
    "Y_train= np.array(Y_train)\n",
    "print (Y_train[:10])\n",
    "X_test= np.array(X_test)\n",
    "Y_test= np.array(Y_test)\n",
    "Y_train= [ord(char)-65 for char in Y_train]\n",
    "Y_test= [ord(char)-65 for char in Y_test]\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndex(num, cum):\n",
    "    index= -1\n",
    "    for i in range(len(cum)):\n",
    "        if(num<= cum[i]):\n",
    "            return i #between 0to149 format\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAcc(yy_train, probsmatrix):\n",
    "    trainpred= []\n",
    "    for i in range(len(yy_train)):\n",
    "        trainpred.append(np.argmax(probsmatrix[i]))\n",
    "    trainpred= np.array(trainpred)\n",
    "    #print (np.unique(trainpred))\n",
    "    return ((yy_train== trainpred).sum())/len(yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boosting(X_train, Y_train, X_test, N):\n",
    "    originaldt= np.zeros(len(X_train))\n",
    "    originaldt+= 1/len(X_train)\n",
    "    uniq= np.unique(Y_train)\n",
    "    probstest= np.zeros([len(X_test), len(uniq)])\n",
    "    probstrain= np.zeros([len(X_train), len(uniq)])\n",
    "    print (originaldt)\n",
    "    alphas= []\n",
    "    for i in range(N):\n",
    "        print (str(i) +  \" \" + \"Iteration\")\n",
    "        indices= []\n",
    "        #labeltemp= np.zeros(len(Y_train))\n",
    "        cum= np.cumsum(originaldt)\n",
    "        print (cum)\n",
    "        #temp= np.zeros([len(X_train), len(X_train[0])])\n",
    "#         for j in range(len(X_train)):\n",
    "#             num= random.uniform(0, 1)\n",
    "#             a= getIndex(num, cum)\n",
    "#             indices.append(a)\n",
    "#             labeltemp[j]= Y_train[a]\n",
    "#             temp[j]= X_train[a]\n",
    "        \n",
    "#         originaldt=np.zeros(len(X_train))\n",
    "#         originaldt+= 1/len(X_train)\n",
    "        #print (labeltemp.shape, temp.shape)\n",
    "        clf= DecisionTreeClassifier(random_state= 0, max_depth= 2, max_leaf_nodes= 5)\n",
    "        #clf= clf.fit(temp, labeltemp)\n",
    "        clf= clf.fit(X_train, Y_train, sample_weight= originaldt)\n",
    "        #pred= clf.predict(temp)\n",
    "        pred= clf.predict(X_train)\n",
    "        pred= np.array(pred)\n",
    "        error= (((pred!= Y_train)).sum())/len(pred)\n",
    "        print (error)\n",
    "        alpha= abs(1/2*math.log((1-error)/(error)))\n",
    "        alphas.append(alpha)\n",
    "        print (alpha)\n",
    "        for j in range(len(pred)):\n",
    "            if(pred[j]== Y_train[j]):\n",
    "                originaldt[j]= originaldt[j]*math.exp(-alpha)\n",
    "            else:\n",
    "                originaldt[j]= originaldt[j]*math.exp(alpha)\n",
    "        \n",
    "        #now normalize the weights updated\n",
    "        #print (originaldt)\n",
    "        originaldt= originaldt/np.sum(originaldt)#normalize\n",
    "    \n",
    "        #for th final training and testing accuracies and errors on the dataset\n",
    "        probstest+= clf.predict_proba(X_test)*alphas[i]#multiply by aplhas?\n",
    "        probstrain+= clf.predict_proba(X_train)*alphas[i]#multiply by aplhas?\n",
    "    \n",
    "    print (probstrain.shape, probstest.shape)\n",
    "    return (probstrain, probstest)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.14285714e-05 7.14285714e-05 7.14285714e-05 ... 7.14285714e-05\n",
      " 7.14285714e-05 7.14285714e-05]\n",
      "0 Iteration\n",
      "[7.14285714e-05 1.42857143e-04 2.14285714e-04 ... 9.99857143e-01\n",
      " 9.99928571e-01 1.00000000e+00]\n",
      "0.8397857142857142\n",
      "0.8283172761737663\n",
      "1 Iteration\n",
      "[8.20686590e-05 1.64137318e-04 2.46205977e-04 ... 9.99835863e-01\n",
      " 9.99917931e-01 1.00000000e+00]\n",
      "0.8484285714285714\n",
      "0.8611644547009385\n",
      "2 Iteration\n",
      "[9.57669668e-05 1.91533934e-04 2.08642664e-04 ... 9.99887124e-01\n",
      " 9.99982891e-01 1.00000000e+00]\n",
      "0.8535714285714285\n",
      "0.8814457426136013\n",
      "3 Iteration\n",
      "[1.14368222e-04 1.33987875e-04 1.54419713e-04 ... 9.99865200e-01\n",
      " 9.99979568e-01 1.00000000e+00]\n",
      "0.8655714285714285\n",
      "0.9311784546798045\n",
      "4 Iteration\n",
      "[1.39782453e-04 1.63761870e-04 1.88733950e-04 ... 9.99835245e-01\n",
      " 9.99975028e-01 1.00000000e+00]\n",
      "0.8567142857142858\n",
      "0.8941319176032873\n",
      "5 Iteration\n",
      "[1.73719737e-04 2.03521031e-04 2.34555993e-04 ... 9.99795245e-01\n",
      " 9.99968965e-01 1.00000000e+00]\n",
      "0.8816428571428572\n",
      "1.004040181158683\n",
      "6 Iteration\n",
      "[2.82121452e-05 6.42633917e-05 6.93034803e-05 ... 9.99934244e-01\n",
      " 9.99962456e-01 1.00000000e+00]\n",
      "0.8695714285714286\n",
      "0.9485873739494779\n",
      "7 Iteration\n",
      "[3.30255261e-05 3.93554924e-05 4.52554896e-05 ... 9.99923025e-01\n",
      " 9.99956051e-01 1.00000000e+00]\n",
      "0.8703571428571428\n",
      "0.9520601096801776\n",
      "8 Iteration\n",
      "[3.85357812e-05 4.59218920e-05 5.28062941e-05 ... 9.99910182e-01\n",
      " 9.99948718e-01 1.00000000e+00]\n",
      "0.8484285714285714\n",
      "0.8611644547009385\n",
      "9 Iteration\n",
      "[4.45938415e-05 5.31410941e-05 6.11077662e-05 ... 9.99932690e-01\n",
      " 9.99940656e-01 1.00000000e+00]\n",
      "0.8547857142857143\n",
      "0.8863201634725848\n",
      "(14000, 26) (6000, 26)\n"
     ]
    }
   ],
   "source": [
    "# clf= DecisionTreeClassifier(max_depth= 2, max_leaf_nodes= 5)\n",
    "# clf= clf.fit(X_train, Y_train)\n",
    "# pred= clf.predict(X_test)\n",
    "# print (np.unique(pred))\n",
    "probstrain, probstest= boosting(X_train, Y_train, X_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  4  5  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24 25]\n",
      "[ 0  2  4  5  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24 25]\n",
      "The accuracy on the train set for Boosting is: 0.5058571428571429\n",
      "The accuracy on the test set for Boosting is: 0.5161666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy= getAcc(Y_test, probstest)\n",
    "accuracy2= getAcc(Y_train, probstrain)\n",
    "print (\"The accuracy on the train set for Boosting is: \" + str(accuracy2))\n",
    "print (\"The accuracy on the test set for Boosting is: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n",
      "2800 11200\n",
      "[8.92857143e-05 8.92857143e-05 8.92857143e-05 ... 8.92857143e-05\n",
      " 8.92857143e-05 8.92857143e-05]\n",
      "0 Iteration\n",
      "[8.92857143e-05 1.78571429e-04 2.67857143e-04 ... 9.99821429e-01\n",
      " 9.99910714e-01 1.00000000e+00]\n",
      "0.8385714285714285\n",
      "0.8238185005578778\n",
      "1 Iteration\n",
      "[1.02668902e-04 2.05337803e-04 2.25102004e-04 ... 9.99794662e-01\n",
      " 9.99897331e-01 1.00000000e+00]\n",
      "0.8526785714285714\n",
      "0.8778829332900747\n",
      "2 Iteration\n",
      "[1.19401185e-04 2.38802371e-04 2.61787607e-04 ... 9.99859969e-01\n",
      " 9.99979370e-01 1.00000000e+00]\n",
      "0.8502678571428571\n",
      "0.8683517211854185\n",
      "3 Iteration\n",
      "[1.42991026e-04 2.85982051e-04 3.13508433e-04 ... 9.99832304e-01\n",
      " 9.99975295e-01 1.00000000e+00]\n",
      "0.8657142857142858\n",
      "0.9317926018996555\n",
      "4 Iteration\n",
      "[2.71051144e-05 2.01846596e-04 2.35485076e-04 ... 9.99942704e-01\n",
      " 9.99969809e-01 1.00000000e+00]\n",
      "0.8525\n",
      "0.8771725166888988\n",
      "5 Iteration\n",
      "[3.38363711e-05 2.51972976e-04 2.93965202e-04 ... 9.99928475e-01\n",
      " 9.99962311e-01 1.00000000e+00]\n",
      "0.8759821428571428\n",
      "0.9774600707045233\n",
      "6 Iteration\n",
      "[5.90924442e-06 2.74993170e-04 3.26792971e-04 ... 9.99947600e-01\n",
      " 9.99953509e-01 1.00000000e+00]\n",
      "0.8614285714285714\n",
      "0.9136031091119013\n",
      "7 Iteration\n",
      "[6.76819317e-06 3.14965292e-04 3.24509135e-04 ... 9.99984666e-01\n",
      " 9.99991434e-01 1.00000000e+00]\n",
      "0.87375\n",
      "0.9672651126962755\n",
      "8 Iteration\n",
      "[7.85644234e-06 3.65608160e-04 3.76686546e-04 ... 9.99982201e-01\n",
      " 9.99990057e-01 1.00000000e+00]\n",
      "0.8601785714285715\n",
      "0.908386955319709\n",
      "9 Iteration\n",
      "[9.11142181e-06 4.24010006e-04 4.36858041e-04 ... 9.99979357e-01\n",
      " 9.99988469e-01 1.00000000e+00]\n",
      "0.8914285714285715\n",
      "1.0527085140415484\n",
      "(11200, 26) (2800, 26)\n",
      "[ 0  2  4  5  6  7  8  9 10 11 12 13 14 15 17 18 20 21 22 24 25]\n",
      "The accuracy on validation set for 0 fold is: 0.38571428571428573\n",
      "[8.92857143e-05 8.92857143e-05 8.92857143e-05 ... 8.92857143e-05\n",
      " 8.92857143e-05 8.92857143e-05]\n",
      "0 Iteration\n",
      "[8.92857143e-05 1.78571429e-04 2.67857143e-04 ... 9.99821429e-01\n",
      " 9.99910714e-01 1.00000000e+00]\n",
      "0.8385714285714285\n",
      "0.8238185005578778\n",
      "1 Iteration\n",
      "[1.02668902e-04 2.05337803e-04 2.25102004e-04 ... 9.99794662e-01\n",
      " 9.99897331e-01 1.00000000e+00]\n",
      "0.8526785714285714\n",
      "0.8778829332900747\n",
      "2 Iteration\n",
      "[1.19401185e-04 2.38802371e-04 2.61787607e-04 ... 9.99859969e-01\n",
      " 9.99979370e-01 1.00000000e+00]\n",
      "0.8502678571428571\n",
      "0.8683517211854185\n",
      "3 Iteration\n",
      "[1.42991026e-04 2.85982051e-04 3.13508433e-04 ... 9.99832304e-01\n",
      " 9.99975295e-01 1.00000000e+00]\n",
      "0.8657142857142858\n",
      "0.9317926018996555\n",
      "4 Iteration\n",
      "[2.71051144e-05 2.01846596e-04 2.35485076e-04 ... 9.99942704e-01\n",
      " 9.99969809e-01 1.00000000e+00]\n",
      "0.8525\n",
      "0.8771725166888988\n",
      "5 Iteration\n",
      "[3.38363711e-05 2.51972976e-04 2.93965202e-04 ... 9.99928475e-01\n",
      " 9.99962311e-01 1.00000000e+00]\n",
      "0.8759821428571428\n",
      "0.9774600707045233\n",
      "6 Iteration\n",
      "[5.90924442e-06 2.74993170e-04 3.26792971e-04 ... 9.99947600e-01\n",
      " 9.99953509e-01 1.00000000e+00]\n",
      "0.8614285714285714\n",
      "0.9136031091119013\n",
      "7 Iteration\n",
      "[6.76819317e-06 3.14965292e-04 3.24509135e-04 ... 9.99984666e-01\n",
      " 9.99991434e-01 1.00000000e+00]\n",
      "0.87375\n",
      "0.9672651126962755\n",
      "8 Iteration\n",
      "[7.85644234e-06 3.65608160e-04 3.76686546e-04 ... 9.99982201e-01\n",
      " 9.99990057e-01 1.00000000e+00]\n",
      "0.8601785714285715\n",
      "0.908386955319709\n",
      "9 Iteration\n",
      "[9.11142181e-06 4.24010006e-04 4.36858041e-04 ... 9.99979357e-01\n",
      " 9.99988469e-01 1.00000000e+00]\n",
      "0.8914285714285715\n",
      "1.0527085140415484\n",
      "(11200, 26) (6000, 26)\n",
      "[ 0  2  4  5  6  7  8  9 10 11 12 13 14 15 17 18 20 21 22 24 25]\n",
      "2800 11200\n",
      "[8.92857143e-05 8.92857143e-05 8.92857143e-05 ... 8.92857143e-05\n",
      " 8.92857143e-05 8.92857143e-05]\n",
      "0 Iteration\n",
      "[8.92857143e-05 1.78571429e-04 2.67857143e-04 ... 9.99821429e-01\n",
      " 9.99910714e-01 1.00000000e+00]\n",
      "0.84125\n",
      "0.8337791215930686\n",
      "1 Iteration\n",
      "[1.02485041e-04 2.04970083e-04 3.07455124e-04 ... 9.99795030e-01\n",
      " 9.99897515e-01 1.00000000e+00]\n",
      "0.8489285714285715\n",
      "0.8631111441569582\n",
      "2 Iteration\n",
      "[1.19522549e-04 2.39045098e-04 2.60314782e-04 ... 9.99859208e-01\n",
      " 9.99978730e-01 1.00000000e+00]\n",
      "0.8532142857142857\n",
      "0.8800184664147874\n",
      "3 Iteration\n",
      "[1.42745936e-04 1.67303734e-04 1.92706145e-04 ... 9.99831852e-01\n",
      " 9.99974598e-01 1.00000000e+00]\n",
      "0.864375\n",
      "0.9260564890621493\n",
      "4 Iteration\n",
      "[1.74678820e-04 2.04730303e-04 2.35815344e-04 ... 9.99794236e-01\n",
      " 9.99968915e-01 1.00000000e+00]\n",
      "0.8925\n",
      "1.0582678330430382\n",
      "5 Iteration\n",
      "[2.58150513e-05 6.26871981e-05 1.00827483e-04 ... 9.99747535e-01\n",
      " 9.99961860e-01 1.00000000e+00]\n",
      "0.876875\n",
      "0.981582175682236\n",
      "6 Iteration\n",
      "[3.14630760e-05 7.64024079e-05 1.22887332e-04 ... 9.99916837e-01\n",
      " 9.99953515e-01 1.00000000e+00]\n",
      "0.8790178571428572\n",
      "0.9915811288797125\n",
      "7 Iteration\n",
      "[3.74158791e-05 4.47712565e-05 5.23796064e-05 ... 9.99901102e-01\n",
      " 9.99944720e-01 1.00000000e+00]\n",
      "0.8573214285714286\n",
      "0.8966092813823329\n",
      "8 Iteration\n",
      "[4.35264173e-05 5.20830311e-05 6.09339313e-05 ... 9.99938556e-01\n",
      " 9.99989298e-01 1.00000000e+00]\n",
      "0.8861607142857143\n",
      "1.0260553239814325\n",
      "9 Iteration\n",
      "[4.96428333e-05 5.94018389e-05 6.94964846e-05 ... 9.99929922e-01\n",
      " 9.99987794e-01 1.00000000e+00]\n",
      "0.8658035714285715\n",
      "0.932176724275786\n",
      "(11200, 26) (2800, 26)\n",
      "[ 0  2  4  5  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24 25]\n",
      "The accuracy on validation set for 1 fold is: 0.43857142857142856\n",
      "[8.92857143e-05 8.92857143e-05 8.92857143e-05 ... 8.92857143e-05\n",
      " 8.92857143e-05 8.92857143e-05]\n",
      "0 Iteration\n",
      "[8.92857143e-05 1.78571429e-04 2.67857143e-04 ... 9.99821429e-01\n",
      " 9.99910714e-01 1.00000000e+00]\n",
      "0.84125\n",
      "0.8337791215930686\n",
      "1 Iteration\n",
      "[1.02485041e-04 2.04970083e-04 3.07455124e-04 ... 9.99795030e-01\n",
      " 9.99897515e-01 1.00000000e+00]\n",
      "0.8489285714285715\n",
      "0.8631111441569582\n",
      "2 Iteration\n",
      "[1.19522549e-04 2.39045098e-04 2.60314782e-04 ... 9.99859208e-01\n",
      " 9.99978730e-01 1.00000000e+00]\n",
      "0.8532142857142857\n",
      "0.8800184664147874\n",
      "3 Iteration\n",
      "[1.42745936e-04 1.67303734e-04 1.92706145e-04 ... 9.99831852e-01\n",
      " 9.99974598e-01 1.00000000e+00]\n",
      "0.864375\n",
      "0.9260564890621493\n",
      "4 Iteration\n",
      "[1.74678820e-04 2.04730303e-04 2.35815344e-04 ... 9.99794236e-01\n",
      " 9.99968915e-01 1.00000000e+00]\n",
      "0.8925\n",
      "1.0582678330430382\n",
      "5 Iteration\n",
      "[2.58150513e-05 6.26871981e-05 1.00827483e-04 ... 9.99747535e-01\n",
      " 9.99961860e-01 1.00000000e+00]\n",
      "0.876875\n",
      "0.981582175682236\n",
      "6 Iteration\n",
      "[3.14630760e-05 7.64024079e-05 1.22887332e-04 ... 9.99916837e-01\n",
      " 9.99953515e-01 1.00000000e+00]\n",
      "0.8790178571428572\n",
      "0.9915811288797125\n",
      "7 Iteration\n",
      "[3.74158791e-05 4.47712565e-05 5.23796064e-05 ... 9.99901102e-01\n",
      " 9.99944720e-01 1.00000000e+00]\n",
      "0.8573214285714286\n",
      "0.8966092813823329\n",
      "8 Iteration\n",
      "[4.35264173e-05 5.20830311e-05 6.09339313e-05 ... 9.99938556e-01\n",
      " 9.99989298e-01 1.00000000e+00]\n",
      "0.8861607142857143\n",
      "1.0260553239814325\n",
      "9 Iteration\n",
      "[4.96428333e-05 5.94018389e-05 6.94964846e-05 ... 9.99929922e-01\n",
      " 9.99987794e-01 1.00000000e+00]\n",
      "0.8658035714285715\n",
      "0.932176724275786\n",
      "(11200, 26) (6000, 26)\n",
      "[ 0  2  4  5  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24 25]\n",
      "2800 11200\n",
      "[8.92857143e-05 8.92857143e-05 8.92857143e-05 ... 8.92857143e-05\n",
      " 8.92857143e-05 8.92857143e-05]\n",
      "0 Iteration\n",
      "[8.92857143e-05 1.78571429e-04 2.67857143e-04 ... 9.99821429e-01\n",
      " 9.99910714e-01 1.00000000e+00]\n",
      "0.83875\n",
      "0.8244783663050048\n",
      "1 Iteration\n",
      "[1.02656713e-04 2.05313426e-04 3.07970139e-04 ... 9.99794687e-01\n",
      " 9.99897343e-01 1.00000000e+00]\n",
      "0.8491071428571428\n",
      "0.8638076738111583\n",
      "2 Iteration\n",
      "[1.19738537e-04 1.41016994e-04 2.60755531e-04 ... 9.99858983e-01\n",
      " 9.99978722e-01 1.00000000e+00]\n",
      "0.8566964285714286\n",
      "0.8940591864388421\n",
      "3 Iteration\n",
      "[1.42551555e-04 1.67884060e-04 1.91729318e-04 ... 9.99832116e-01\n",
      " 9.99974667e-01 1.00000000e+00]\n",
      "0.8752678571428572\n",
      "0.9741806905023822\n",
      "4 Iteration\n",
      "[1.71907297e-04 2.02456543e-04 2.31212271e-04 ... 9.99797543e-01\n",
      " 9.99969451e-01 1.00000000e+00]\n",
      "0.886875\n",
      "1.0296053229471083\n",
      "5 Iteration\n",
      "[2.12237601e-04 2.49953852e-04 2.85455817e-04 ... 9.99750046e-01\n",
      " 9.99962284e-01 1.00000000e+00]\n",
      "0.8609821428571428\n",
      "0.9117356853381928\n",
      "6 Iteration\n",
      "[4.16776156e-05 8.75480240e-05 1.30725423e-04 ... 9.99912452e-01\n",
      " 9.99954130e-01 1.00000000e+00]\n",
      "0.8683035714285714\n",
      "0.9430209498563632\n",
      "7 Iteration\n",
      "[4.93345480e-05 1.03632181e-04 1.11384063e-04 ... 9.99942430e-01\n",
      " 9.99991765e-01 1.00000000e+00]\n",
      "0.8444642857142857\n",
      "0.8459135328956863\n",
      "8 Iteration\n",
      "[5.87794523e-05 7.06947286e-05 7.99306782e-05 ... 9.99931409e-01\n",
      " 9.99990188e-01 1.00000000e+00]\n",
      "0.8536607142857143\n",
      "0.8818030121708084\n",
      "9 Iteration\n",
      "[1.17994367e-05 2.57523284e-05 3.65677053e-05 ... 9.99919679e-01\n",
      " 9.99988510e-01 1.00000000e+00]\n",
      "0.8596428571428572\n",
      "0.9061634129569054\n",
      "(11200, 26) (2800, 26)\n",
      "[ 0  2  3  5  6  7  8  9 10 11 12 13 14 15 18 19 21 22 23 24 25]\n",
      "The accuracy on validation set for 2 fold is: 0.4057142857142857\n",
      "[8.92857143e-05 8.92857143e-05 8.92857143e-05 ... 8.92857143e-05\n",
      " 8.92857143e-05 8.92857143e-05]\n",
      "0 Iteration\n",
      "[8.92857143e-05 1.78571429e-04 2.67857143e-04 ... 9.99821429e-01\n",
      " 9.99910714e-01 1.00000000e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83875\n",
      "0.8244783663050048\n",
      "1 Iteration\n",
      "[1.02656713e-04 2.05313426e-04 3.07970139e-04 ... 9.99794687e-01\n",
      " 9.99897343e-01 1.00000000e+00]\n",
      "0.8491071428571428\n",
      "0.8638076738111583\n",
      "2 Iteration\n",
      "[1.19738537e-04 1.41016994e-04 2.60755531e-04 ... 9.99858983e-01\n",
      " 9.99978722e-01 1.00000000e+00]\n",
      "0.8566964285714286\n",
      "0.8940591864388421\n",
      "3 Iteration\n",
      "[1.42551555e-04 1.67884060e-04 1.91729318e-04 ... 9.99832116e-01\n",
      " 9.99974667e-01 1.00000000e+00]\n",
      "0.8752678571428572\n",
      "0.9741806905023822\n",
      "4 Iteration\n",
      "[1.71907297e-04 2.02456543e-04 2.31212271e-04 ... 9.99797543e-01\n",
      " 9.99969451e-01 1.00000000e+00]\n",
      "0.886875\n",
      "1.0296053229471083\n",
      "5 Iteration\n",
      "[2.12237601e-04 2.49953852e-04 2.85455817e-04 ... 9.99750046e-01\n",
      " 9.99962284e-01 1.00000000e+00]\n",
      "0.8609821428571428\n",
      "0.9117356853381928\n",
      "6 Iteration\n",
      "[4.16776156e-05 8.75480240e-05 1.30725423e-04 ... 9.99912452e-01\n",
      " 9.99954130e-01 1.00000000e+00]\n",
      "0.8683035714285714\n",
      "0.9430209498563632\n",
      "7 Iteration\n",
      "[4.93345480e-05 1.03632181e-04 1.11384063e-04 ... 9.99942430e-01\n",
      " 9.99991765e-01 1.00000000e+00]\n",
      "0.8444642857142857\n",
      "0.8459135328956863\n",
      "8 Iteration\n",
      "[5.87794523e-05 7.06947286e-05 7.99306782e-05 ... 9.99931409e-01\n",
      " 9.99990188e-01 1.00000000e+00]\n",
      "0.8536607142857143\n",
      "0.8818030121708084\n",
      "9 Iteration\n",
      "[1.17994367e-05 2.57523284e-05 3.65677053e-05 ... 9.99919679e-01\n",
      " 9.99988510e-01 1.00000000e+00]\n",
      "0.8596428571428572\n",
      "0.9061634129569054\n",
      "(11200, 26) (6000, 26)\n",
      "[ 0  2  3  5  6  7  8  9 10 11 12 13 14 15 18 19 21 22 23 24 25]\n",
      "2800 11200\n",
      "[8.92857143e-05 8.92857143e-05 8.92857143e-05 ... 8.92857143e-05\n",
      " 8.92857143e-05 8.92857143e-05]\n",
      "0 Iteration\n",
      "[8.92857143e-05 1.78571429e-04 2.67857143e-04 ... 9.99821429e-01\n",
      " 9.99910714e-01 1.00000000e+00]\n",
      "0.8383928571428572\n",
      "0.8231592239712187\n",
      "1 Iteration\n",
      "[1.02681081e-04 2.05362161e-04 3.08043242e-04 ... 9.99794638e-01\n",
      " 9.99897319e-01 1.00000000e+00]\n",
      "0.8472321428571429\n",
      "0.8565276190407826\n",
      "2 Iteration\n",
      "[1.19955716e-04 2.39911431e-04 2.61541132e-04 ... 9.99858415e-01\n",
      " 9.99978370e-01 1.00000000e+00]\n",
      "0.8495535714285715\n",
      "0.865551968471894\n",
      "3 Iteration\n",
      "[1.43888941e-04 1.69370062e-04 1.95315260e-04 ... 9.99830166e-01\n",
      " 9.99974055e-01 1.00000000e+00]\n",
      "0.8567857142857143\n",
      "0.8944229177665626\n",
      "4 Iteration\n",
      "[1.74023128e-04 2.04840676e-04 2.36219490e-04 ... 9.99939533e-01\n",
      " 9.99968621e-01 1.00000000e+00]\n",
      "0.8703571428571428\n",
      "0.9520601096801776\n",
      "5 Iteration\n",
      "[3.17887198e-05 6.95818667e-05 7.53138195e-05 ... 9.99925846e-01\n",
      " 9.99961519e-01 1.00000000e+00]\n",
      "0.8883928571428571\n",
      "1.0372144999281456\n",
      "6 Iteration\n",
      "[3.99221883e-05 8.73850976e-05 9.45836290e-05 ... 9.99906873e-01\n",
      " 9.99951673e-01 1.00000000e+00]\n",
      "0.8783928571428572\n",
      "0.988649115322914\n",
      "7 Iteration\n",
      "[4.64131113e-05 5.40523660e-05 6.24213019e-05 ... 9.99891731e-01\n",
      " 9.99943815e-01 1.00000000e+00]\n",
      "0.8683928571428572\n",
      "0.9434114591072248\n",
      "8 Iteration\n",
      "[5.31533851e-05 6.19020390e-05 7.14863410e-05 ... 9.99876008e-01\n",
      " 9.99935656e-01 1.00000000e+00]\n",
      "0.8680357142857142\n",
      "0.9418507680486267\n",
      "9 Iteration\n",
      "[6.20275004e-05 7.22367680e-05 8.34211977e-05 ... 9.99855307e-01\n",
      " 9.99924913e-01 1.00000000e+00]\n",
      "0.8664285714285714\n",
      "0.9348716460447318\n",
      "(11200, 26) (2800, 26)\n",
      "[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 21 22 23 24 25]\n",
      "The accuracy on validation set for 3 fold is: 0.38785714285714284\n",
      "[8.92857143e-05 8.92857143e-05 8.92857143e-05 ... 8.92857143e-05\n",
      " 8.92857143e-05 8.92857143e-05]\n",
      "0 Iteration\n",
      "[8.92857143e-05 1.78571429e-04 2.67857143e-04 ... 9.99821429e-01\n",
      " 9.99910714e-01 1.00000000e+00]\n",
      "0.8383928571428572\n",
      "0.8231592239712187\n",
      "1 Iteration\n",
      "[1.02681081e-04 2.05362161e-04 3.08043242e-04 ... 9.99794638e-01\n",
      " 9.99897319e-01 1.00000000e+00]\n",
      "0.8472321428571429\n",
      "0.8565276190407826\n",
      "2 Iteration\n",
      "[1.19955716e-04 2.39911431e-04 2.61541132e-04 ... 9.99858415e-01\n",
      " 9.99978370e-01 1.00000000e+00]\n",
      "0.8495535714285715\n",
      "0.865551968471894\n",
      "3 Iteration\n",
      "[1.43888941e-04 1.69370062e-04 1.95315260e-04 ... 9.99830166e-01\n",
      " 9.99974055e-01 1.00000000e+00]\n",
      "0.8567857142857143\n",
      "0.8944229177665626\n",
      "4 Iteration\n",
      "[1.74023128e-04 2.04840676e-04 2.36219490e-04 ... 9.99939533e-01\n",
      " 9.99968621e-01 1.00000000e+00]\n",
      "0.8703571428571428\n",
      "0.9520601096801776\n",
      "5 Iteration\n",
      "[3.17887198e-05 6.95818667e-05 7.53138195e-05 ... 9.99925846e-01\n",
      " 9.99961519e-01 1.00000000e+00]\n",
      "0.8883928571428571\n",
      "1.0372144999281456\n",
      "6 Iteration\n",
      "[3.99221883e-05 8.73850976e-05 9.45836290e-05 ... 9.99906873e-01\n",
      " 9.99951673e-01 1.00000000e+00]\n",
      "0.8783928571428572\n",
      "0.988649115322914\n",
      "7 Iteration\n",
      "[4.64131113e-05 5.40523660e-05 6.24213019e-05 ... 9.99891731e-01\n",
      " 9.99943815e-01 1.00000000e+00]\n",
      "0.8683928571428572\n",
      "0.9434114591072248\n",
      "8 Iteration\n",
      "[5.31533851e-05 6.19020390e-05 7.14863410e-05 ... 9.99876008e-01\n",
      " 9.99935656e-01 1.00000000e+00]\n",
      "0.8680357142857142\n",
      "0.9418507680486267\n",
      "9 Iteration\n",
      "[6.20275004e-05 7.22367680e-05 8.34211977e-05 ... 9.99855307e-01\n",
      " 9.99924913e-01 1.00000000e+00]\n",
      "0.8664285714285714\n",
      "0.9348716460447318\n",
      "(11200, 26) (6000, 26)\n",
      "[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 21 22 23 24 25]\n",
      "2800 11200\n",
      "[8.92857143e-05 8.92857143e-05 8.92857143e-05 ... 8.92857143e-05\n",
      " 8.92857143e-05 8.92857143e-05]\n",
      "0 Iteration\n",
      "[8.92857143e-05 1.78571429e-04 2.67857143e-04 ... 9.99821429e-01\n",
      " 9.99910714e-01 1.00000000e+00]\n",
      "0.8395535714285715\n",
      "0.827455089746759\n",
      "1 Iteration\n",
      "[1.02601741e-04 2.05203483e-04 3.07805224e-04 ... 9.99877790e-01\n",
      " 9.99897398e-01 1.00000000e+00]\n",
      "0.8475892857142857\n",
      "0.8579086205436789\n",
      "2 Iteration\n",
      "[1.19812560e-04 2.39625119e-04 2.61169419e-04 ... 9.99955558e-01\n",
      " 9.99978456e-01 1.00000000e+00]\n",
      "0.8533035714285714\n",
      "0.8803750156144556\n",
      "3 Iteration\n",
      "[1.43146951e-04 1.67756184e-04 1.93496397e-04 ... 9.99946903e-01\n",
      " 9.99974260e-01 1.00000000e+00]\n",
      "0.8636607142857143\n",
      "0.9230167364819575\n",
      "4 Iteration\n",
      "[1.75442180e-04 2.05603475e-04 2.37150910e-04 ... 9.99934924e-01\n",
      " 9.99968453e-01 1.00000000e+00]\n",
      "0.865\n",
      "0.928727364246725\n",
      "5 Iteration\n",
      "[2.18088534e-04 2.55581415e-04 2.94797377e-04 ... 9.99919105e-01\n",
      " 9.99960784e-01 1.00000000e+00]\n",
      "0.8767857142857143\n",
      "0.9811688115986306\n",
      "6 Iteration\n",
      "[3.71021618e-05 8.24908462e-05 8.91624348e-05 ... 9.99942872e-01\n",
      " 9.99993328e-01 1.00000000e+00]\n",
      "0.8500892857142858\n",
      "0.8676507536040755\n",
      "7 Iteration\n",
      "[4.35030228e-05 9.67221580e-05 1.04544728e-04 ... 9.99933017e-01\n",
      " 9.99992177e-01 1.00000000e+00]\n",
      "0.8679464285714286\n",
      "0.9414611550551346\n",
      "8 Iteration\n",
      "[5.05630637e-05 1.12419053e-04 1.21511137e-04 ... 9.99922146e-01\n",
      " 9.99990908e-01 1.00000000e+00]\n",
      "0.8488392857142857\n",
      "0.8627631331129474\n",
      "9 Iteration\n",
      "[5.82291384e-05 1.29463370e-04 1.39933942e-04 ... 9.99975428e-01\n",
      " 9.99989529e-01 1.00000000e+00]\n",
      "0.8830357142857143\n",
      "1.0107485042107802\n",
      "(11200, 26) (2800, 26)\n",
      "[ 0  2  4  5  6  7  8  9 10 11 12 13 14 15 18 19 20 21 22 23 24 25]\n",
      "The accuracy on validation set for 4 fold is: 0.4789285714285714\n",
      "[8.92857143e-05 8.92857143e-05 8.92857143e-05 ... 8.92857143e-05\n",
      " 8.92857143e-05 8.92857143e-05]\n",
      "0 Iteration\n",
      "[8.92857143e-05 1.78571429e-04 2.67857143e-04 ... 9.99821429e-01\n",
      " 9.99910714e-01 1.00000000e+00]\n",
      "0.8395535714285715\n",
      "0.827455089746759\n",
      "1 Iteration\n",
      "[1.02601741e-04 2.05203483e-04 3.07805224e-04 ... 9.99877790e-01\n",
      " 9.99897398e-01 1.00000000e+00]\n",
      "0.8475892857142857\n",
      "0.8579086205436789\n",
      "2 Iteration\n",
      "[1.19812560e-04 2.39625119e-04 2.61169419e-04 ... 9.99955558e-01\n",
      " 9.99978456e-01 1.00000000e+00]\n",
      "0.8533035714285714\n",
      "0.8803750156144556\n",
      "3 Iteration\n",
      "[1.43146951e-04 1.67756184e-04 1.93496397e-04 ... 9.99946903e-01\n",
      " 9.99974260e-01 1.00000000e+00]\n",
      "0.8636607142857143\n",
      "0.9230167364819575\n",
      "4 Iteration\n",
      "[1.75442180e-04 2.05603475e-04 2.37150910e-04 ... 9.99934924e-01\n",
      " 9.99968453e-01 1.00000000e+00]\n",
      "0.865\n",
      "0.928727364246725\n",
      "5 Iteration\n",
      "[2.18088534e-04 2.55581415e-04 2.94797377e-04 ... 9.99919105e-01\n",
      " 9.99960784e-01 1.00000000e+00]\n",
      "0.8767857142857143\n",
      "0.9811688115986306\n",
      "6 Iteration\n",
      "[3.71021618e-05 8.24908462e-05 8.91624348e-05 ... 9.99942872e-01\n",
      " 9.99993328e-01 1.00000000e+00]\n",
      "0.8500892857142858\n",
      "0.8676507536040755\n",
      "7 Iteration\n",
      "[4.35030228e-05 9.67221580e-05 1.04544728e-04 ... 9.99933017e-01\n",
      " 9.99992177e-01 1.00000000e+00]\n",
      "0.8679464285714286\n",
      "0.9414611550551346\n",
      "8 Iteration\n",
      "[5.05630637e-05 1.12419053e-04 1.21511137e-04 ... 9.99922146e-01\n",
      " 9.99990908e-01 1.00000000e+00]\n",
      "0.8488392857142857\n",
      "0.8627631331129474\n",
      "9 Iteration\n",
      "[5.82291384e-05 1.29463370e-04 1.39933942e-04 ... 9.99975428e-01\n",
      " 9.99989529e-01 1.00000000e+00]\n",
      "0.8830357142857143\n",
      "1.0107485042107802\n",
      "(11200, 26) (6000, 26)\n",
      "[ 0  2  4  5  6  7  8  9 10 11 12 13 14 15 18 19 20 21 22 23 24 25]\n",
      "The mean accuracy on Validation set is: 0.4193571428571429\n",
      "The standard deviation of accuracies on Validation set is: 0.03529352140352709\n",
      "The best model during C.V. gives accuraacy of 0.49566666666666664 on the Test set\n"
     ]
    }
   ],
   "source": [
    "#5 fold cross validation for Boosting\n",
    "randarray2= np.arange(len(X_train))\n",
    "breakpt2= round(0.2*len(X_train))\n",
    "print (breakpt2)\n",
    "accuracies= np.zeros(5)\n",
    "testaccuracies= np.zeros(5)\n",
    "for i in range(5):\n",
    "    xx_train= []\n",
    "    yy_train= []\n",
    "    xx_val= []\n",
    "    yy_val= []\n",
    "    for j in range(i*breakpt2, min((i+1)*breakpt2, len(X_train))):\n",
    "        xx_val.append(X_train[randarray2[j]])\n",
    "        yy_val.append(Y_train[randarray2[j]])\n",
    "    for j in range(len(X_train)):\n",
    "        if(j< i*breakpt2 or j>= (i+1)*breakpt2):\n",
    "            xx_train.append(X_train[randarray2[j]])\n",
    "            yy_train.append(Y_train[randarray2[j]])\n",
    "    \n",
    "    print (len(xx_val), len(xx_train))\n",
    "    probs_train, probs_val= boosting(xx_train, yy_train, xx_val, 10)\n",
    "    acc=  getAcc(yy_val, probs_val)\n",
    "    accuracies[i]= acc\n",
    "    print (\"The accuracy on validation set for \" + str(i) + \" fold is: \" + str(acc))\n",
    "    probs_train, probs_test= boosting(xx_train, yy_train, X_test, 10)\n",
    "    acc2=  getAcc(Y_test, probs_test)\n",
    "    testaccuracies[i]= acc2\n",
    "    #print (\"The accuracy on validation set for \" + str(i) + \" fold is: \" + str(acc))\n",
    "\n",
    "print(\"The mean accuracy on Validation set is: \" + str(np.mean(accuracies)))\n",
    "print(\"The standard deviation of accuracies on Validation set is: \" + str(np.std(accuracies)))\n",
    "index= np.argmax(testaccuracies)\n",
    "print(\"The best model during C.V. gives accuraacy of \" + str(testaccuracies[index]) + \" on the Test set\")    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging done right\n",
    "def bagging(X_train, Y_train, X_test, N):\n",
    "    uniq= np.unique(Y_train)\n",
    "    probstrain= np.zeros([len(X_train), len(uniq)])\n",
    "    probstest= np.zeros([len(X_test), len(uniq)])\n",
    "    for i in range(N):\n",
    "        print (str(i) + \" Iteration\")\n",
    "        indices= []\n",
    "        temp= np.zeros([len(X_train), len(X_train[0])])\n",
    "        labeltemp= np.zeros(len(Y_train))\n",
    "        for j in range(len(X_train)):\n",
    "            a= random.randint(0, len(X_train)-1)#since both are inclusive otherwise\n",
    "            indices.append(a)\n",
    "            temp[j]= X_train[a]\n",
    "            labeltemp[j]= Y_train[a]\n",
    "        \n",
    "        \n",
    "        print(labeltemp.shape, temp.shape)\n",
    "        clf= DecisionTreeClassifier(random_state= 0, max_depth= 2, max_leaf_nodes= 5)\n",
    "        clf= clf.fit(temp, labeltemp)\n",
    "        probstest+= clf.predict_proba(X_test)#multiply by alphas??\n",
    "        probstrain+= clf.predict_proba(X_train) \n",
    "    \n",
    "    return (probstrain, probstest)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Iteration\n",
      "(14000,) (14000, 16)\n",
      "1 Iteration\n",
      "(14000,) (14000, 16)\n",
      "2 Iteration\n",
      "(14000,) (14000, 16)\n",
      "3 Iteration\n",
      "(14000,) (14000, 16)\n",
      "4 Iteration\n",
      "(14000,) (14000, 16)\n",
      "5 Iteration\n",
      "(14000,) (14000, 16)\n",
      "6 Iteration\n",
      "(14000,) (14000, 16)\n",
      "7 Iteration\n",
      "(14000,) (14000, 16)\n",
      "8 Iteration\n",
      "(14000,) (14000, 16)\n",
      "9 Iteration\n",
      "(14000,) (14000, 16)\n"
     ]
    }
   ],
   "source": [
    "probstrain, probstest= bagging(X_train, Y_train, X_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  8 11 12 15 16 19 20]\n",
      "[ 0  3  8 11 12 15 16 19 20]\n",
      "The accuracy on the train set for Bagging is: 0.03716666666666667\n",
      "The accuracy on the test set for Bagging is: 0.2555\n"
     ]
    }
   ],
   "source": [
    "accuracy= getAcc(Y_test, probstest)\n",
    "accuracy2= getAcc(Y_test, probstrain)\n",
    "print (\"The accuracy on the train set for Bagging is: \" + str(accuracy2))\n",
    "print (\"The accuracy on the test set for Bagging is: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  8 11 12 15 16 19 20]\n",
      "The accuracy on the test set for Bagging is: 0.2555\n"
     ]
    }
   ],
   "source": [
    "#normalization on Bagging!\n",
    "#MIN-MAX\n",
    "temp= probstest\n",
    "# print (temp.shape)\n",
    "# for i in range(len(probstest)):\n",
    "#     maxx= np.max(temp[i])\n",
    "#     minn= np.min(temp[i])\n",
    "#     temp[i]= (temp[i]-minn)/(maxx-minn)\n",
    "\n",
    "#Z-score normalization\n",
    "# for i in range(len(probstest)):\n",
    "#     mean= np.mean(temp[i])\n",
    "#     std= np.std(temp[i])\n",
    "#     temp[i]= (temp[i]-mean)/std\n",
    "\n",
    "#tanh normalization\n",
    "for i in range(len(probstest)):\n",
    "    temp[i]= np.tanh(temp[i])\n",
    "\n",
    "accuracy= getAcc(Y_test, temp)\n",
    "print (\"The accuracy on the test set for Bagging is: \" + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.96402758 -0.76159416  0.        ]\n",
      "[-2 -1  0]\n"
     ]
    }
   ],
   "source": [
    "a= np.array([1,2,3])\n",
    "b= np.max(a)\n",
    "a-= b\n",
    "print (np.tanh(a))\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 fold cross validation for Bagging\n",
    "randarray2= np.arange(len(X_train))\n",
    "breakpt2= round(0.2*len(X_train))\n",
    "print (breakpt2)\n",
    "valaccuracies= np.zeros(5)\n",
    "testaccuracies= np.zeros(5)\n",
    "for i in range(5):\n",
    "    xx_train= []\n",
    "    yy_train= []\n",
    "    xx_val= []\n",
    "    yy_val= []\n",
    "    for j in range(i*breakpt2, min((i+1)*breakpt2, len(X_train))):\n",
    "        xx_val.append(X_train[randarray2[j]])\n",
    "        yy_val.append(Y_train[randarray2[j]])\n",
    "    for j in range(len(X_train)):\n",
    "        if(j< i*breakpt2 or j>= (i+1)*breakpt2):\n",
    "            xx_train.append(X_train[randarray2[j]])\n",
    "            yy_train.append(Y_train[randarray2[j]])\n",
    "    \n",
    "    print (len(xx_val), len(xx_train))\n",
    "    probs_train, probs_val= bagging(xx_train, yy_train, xx_val, 10)\n",
    "    acc=  getAcc(yy_val, probs_val)\n",
    "    valaccuracies[i]= acc\n",
    "    print (\"The accuracy on validation set for \" + str(i) + \" fold is: \" + str(acc))\n",
    "    probs_train, probs_test= bagging(xx_train, yy_train, X_test, 10)\n",
    "    acc2=  getAcc(Y_test, probs_test)\n",
    "    testaccuracies[i]= acc2\n",
    "    #print (\"The accuracy on validation set for \" + str(i) + \" fold is: \" + str(acc))\n",
    "\n",
    "print(\"The mean accuracy on Validation set is: \" + str(np.mean(valaccuracies)))\n",
    "print(\"The standard deviation of accuracies on Validation set is: \" + str(np.std(valaccuracies)))\n",
    "index= np.argmax(testaccuracies)\n",
    "print(\"The best model during C.V. gives accuraacy of \" + str(testaccuracies[index]) + \" on the Test set\")    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
